{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "is a classification problem\n",
    "\n",
    "line to some curve type where val btw 0 and 1 = sigmoid function \n",
    "P = 1/(1 + e^ -z), \n",
    "cost function =  as non-linear function, so we use log loss formula.\n",
    "\n",
    "## odds ratio in logistic reg\n",
    "\n",
    "equaition of line  z = BX + b\n",
    "                \n",
    "   P = 1/(1 + e^ -z)\n",
    "   \n",
    "   (1 + e^ -z) = 1/p\n",
    "\n",
    "   e^ -z = 1-p / p\n",
    "   \n",
    "   e^ z = p/1-p\n",
    "   \n",
    "   log(e^ z) = log (p/1-p)\n",
    "   \n",
    "   z = log(p/1-p)\n",
    "   \n",
    "   BX+b = log(p/1-p)\n",
    "   \n",
    "   instead of z , we use odds ratio = p/1-p\n",
    "   \n",
    "   by finding the value of z and equate it to odds ratio, and find the proab which lies btw 0 and 1\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 25)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_knn_classification_cleaned_titanic.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
       "0         0  22.0   7.2500         0         0         1           0   \n",
       "1         1  38.0  71.2833         1         0         0           1   \n",
       "2         1  26.0   7.9250         0         0         1           1   \n",
       "3         1  35.0  53.1000         1         0         0           1   \n",
       "4         0  35.0   8.0500         0         0         1           0   \n",
       "\n",
       "   Sex_male  SibSp_0  SibSp_1  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0         1        0        1  ...        1        0        0        0   \n",
       "1         0        0        1  ...        1        0        0        0   \n",
       "2         0        1        0  ...        1        0        0        0   \n",
       "3         0        0        1  ...        1        0        0        0   \n",
       "4         1        1        0  ...        1        0        0        0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0        0        0        0           0           0           1  \n",
       "1        0        0        0           1           0           0  \n",
       "2        0        0        0           0           0           1  \n",
       "3        0        0        0           0           0           1  \n",
       "4        0        0        0           0           0           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seperating independent and dependent varaiables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 24), (891,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = data.drop(['Survived'], axis = 1)\n",
    "y = data['Survived']\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [24, 891]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-c8572242001d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m56\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2116\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2118\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2120\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \"\"\"\n\u001b[0;32m    247\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 212\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [24, 891]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test =train_test_split(x, y, random_state = 56)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalisig (min_max_scaler)\n",
    "    \n",
    "  as the sklearn requires the values to be btw 0 and 1, so we normalise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler as mms\n",
    "scaler = mms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.371701</td>\n",
       "      <td>0.024350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.786378</td>\n",
       "      <td>0.152164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.412821</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  \\\n",
       "0  0.371701  0.024350       0.0       0.0       1.0         1.0       0.0   \n",
       "1  0.334004  0.016908       0.0       0.0       1.0         0.0       1.0   \n",
       "2  0.396833  0.015127       0.0       0.0       1.0         0.0       1.0   \n",
       "3  0.786378  0.152164       1.0       0.0       0.0         1.0       0.0   \n",
       "4  0.334004  0.412821       1.0       0.0       0.0         0.0       1.0   \n",
       "\n",
       "   SibSp_0  SibSp_1  SibSp_2  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "1      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "3      0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "4      1.0      0.0      0.0  ...      0.0      0.0      1.0      0.0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "1      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "2      0.0      0.0      0.0         0.0         1.0         0.0  \n",
       "3      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "4      0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_train_scaled = pd.DataFrame(x_train_scaled, columns = x_train.columns)\n",
    "x_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.448029</td>\n",
       "      <td>0.143462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.405018</td>\n",
       "      <td>0.129995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.415041</td>\n",
       "      <td>0.014110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.390681</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.054164</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  Sex_male  \\\n",
       "0  0.448029  0.143462       0.0       1.0       0.0         0.0       1.0   \n",
       "1  0.405018  0.129995       1.0       0.0       0.0         0.0       1.0   \n",
       "2  0.415041  0.014110       0.0       0.0       1.0         0.0       1.0   \n",
       "3  0.390681  0.025374       0.0       1.0       0.0         1.0       0.0   \n",
       "4  0.419355  0.054164       1.0       0.0       0.0         0.0       1.0   \n",
       "\n",
       "   SibSp_0  SibSp_1  SibSp_2  ...  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0      0.0      0.0      1.0  ...      1.0      0.0      0.0      0.0   \n",
       "1      0.0      1.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "2      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "3      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "4      1.0      0.0      0.0  ...      1.0      0.0      0.0      0.0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "1      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "2      0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "3      0.0      0.0      0.0         0.0         0.0         1.0  \n",
       "4      0.0      0.0      0.0         1.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled = scaler.fit_transform(x_test)\n",
    "x_test_scaled = pd.DataFrame(x_test_scaled, columns = x_test.columns)\n",
    "x_test_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as logReg\n",
    "from sklearn.metrics import mean_squared_log_error as msle\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the instance of  logistic regression\n",
    "\n",
    "logreg = logReg()\n",
    "\n",
    "#fitting the model\n",
    "\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making prediction using predict fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 1 0 0 1 0\n",
      " 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 1 1 1 1 0\n",
      " 1 0 1 1 1 0 1 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 1\n",
      " 1 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 0 1 1 0 0 0\n",
      " 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 1 0 1 0 1 1 1 0 0 0 0\n",
      " 0 0 1 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 0 1\n",
      " 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 1 1\n",
      " 1 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 1 1 0 0 1 1 1 1 1 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0\n",
      " 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1\n",
      " 1 0 0 1 0 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0 0 0 1 0\n",
      " 1 0 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 1\n",
      " 0 0 1 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 1 0 1 1\n",
      " 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 0 0 0 1 1\n",
      " 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2998418413930298, 0.7514910536779325)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precictions using predict function over train set and test\n",
    "\n",
    "train_predict = logreg.predict(x_train)\n",
    "print(train_predict)\n",
    "l = np.sqrt(msle(train_predict, y_train))\n",
    "m = f1_score(train_predict, y_train)\n",
    "l,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 1 1 0 0 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1 1 1 1 1 0 0 1 1 0 1\n",
      " 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1\n",
      " 1 1 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0\n",
      " 1 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 1 1 0 0 1 0 0 0 1 0 1\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 1 1 0 0\n",
      " 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2935641545053478, 0.736842105263158)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = logreg.predict(x_test)\n",
    "print(test_predict)\n",
    "l =np.sqrt(msle(test_predict, y_test))\n",
    "m = f1_score(test_predict, y_test)\n",
    "l, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making predictions using predict_proba fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51807747 0.48192253]\n",
      " [0.90599654 0.09400346]\n",
      " [0.87200636 0.12799364]\n",
      " ...\n",
      " [0.22607554 0.77392446]\n",
      " [0.31667225 0.68332775]\n",
      " [0.04424771 0.95575229]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.48192253, 0.09400346, 0.12799364, 0.77517619, 0.63197608,\n",
       "       0.11729717, 0.84515049, 0.77410272, 0.53660619, 0.08237219,\n",
       "       0.10667104, 0.08593988, 0.12486521, 0.09689127, 0.60642202,\n",
       "       0.08495395, 0.30782465, 0.12097921, 0.0720483 , 0.28556586,\n",
       "       0.10320509, 0.21932357, 0.07151535, 0.59131405, 0.09082367,\n",
       "       0.51428145, 0.08579228, 0.55572919, 0.60444429, 0.12910717,\n",
       "       0.820319  , 0.08597516, 0.58752337, 0.13743317, 0.02228606,\n",
       "       0.57359622, 0.2189523 , 0.1256813 , 0.05898146, 0.28598705,\n",
       "       0.84201218, 0.39166574, 0.20305583, 0.70559965, 0.47667196,\n",
       "       0.94282345, 0.37175431, 0.22126999, 0.16756689, 0.89330988,\n",
       "       0.13335905, 0.63840275, 0.23936439, 0.61134557, 0.34083195,\n",
       "       0.64669947, 0.77903087, 0.29332871, 0.10989962, 0.29912514,\n",
       "       0.58471677, 0.29332871, 0.12450627, 0.45795764, 0.10317854,\n",
       "       0.9760019 , 0.11771106, 0.08593988, 0.86256797, 0.66351388,\n",
       "       0.93046624, 0.74886279, 0.89714864, 0.44936986, 0.84263313,\n",
       "       0.24632399, 0.86427778, 0.54095545, 0.55358947, 0.12910717,\n",
       "       0.52308042, 0.12860464, 0.13128551, 0.0189768 , 0.68678995,\n",
       "       0.94638685, 0.67525832, 0.07561128, 0.27875667, 0.93118156,\n",
       "       0.29003999, 0.13744035, 0.09175207, 0.13744035, 0.20305583,\n",
       "       0.91219642, 0.3419959 , 0.12487183, 0.5550132 , 0.56792383,\n",
       "       0.13744035, 0.12495274, 0.09999443, 0.12801259, 0.12589474,\n",
       "       0.05343071, 0.30087907, 0.04213315, 0.74817323, 0.30261748,\n",
       "       0.23936439, 0.43251537, 0.12567996, 0.13768503, 0.5406843 ,\n",
       "       0.33418663, 0.12481688, 0.92437326, 0.11371022, 0.13673148,\n",
       "       0.49642275, 0.46781815, 0.22464416, 0.40019974, 0.93428092,\n",
       "       0.33162205, 0.38876049, 0.61125618, 0.13743172, 0.67421722,\n",
       "       0.0907229 , 0.09693056, 0.39173512, 0.90490506, 0.12567996,\n",
       "       0.02874713, 0.48350864, 0.0660629 , 0.37899265, 0.90652743,\n",
       "       0.92785308, 0.13202938, 0.63932282, 0.10439352, 0.23234475,\n",
       "       0.2580306 , 0.11011936, 0.92849634, 0.86301418, 0.90540652,\n",
       "       0.51422995, 0.46966761, 0.65387588, 0.07222858, 0.45111541,\n",
       "       0.08598946, 0.44652569, 0.27263644, 0.09294632, 0.801036  ,\n",
       "       0.29572379, 0.27875667, 0.31586077, 0.66045904, 0.04664615,\n",
       "       0.25033468, 0.12101792, 0.82531258, 0.34711463, 0.93780595,\n",
       "       0.05167234, 0.76137971, 0.61163633, 0.28318608, 0.33065469,\n",
       "       0.47645416, 0.50565604, 0.37899932, 0.08071694, 0.09081367,\n",
       "       0.08233628, 0.25636178, 0.04581122, 0.11609393, 0.92428819,\n",
       "       0.36700796, 0.93009832, 0.2834173 , 0.26463745, 0.16977832,\n",
       "       0.14503988, 0.057088  , 0.57020987, 0.31908968, 0.12485726,\n",
       "       0.17272731, 0.29332871, 0.90052418, 0.64044809, 0.27206903,\n",
       "       0.44606496, 0.4029512 , 0.61125618, 0.11367355, 0.21168176,\n",
       "       0.88987204, 0.61740141, 0.08375583, 0.7736837 , 0.13744035,\n",
       "       0.60957154, 0.61125618, 0.1256813 , 0.15854943, 0.94421885,\n",
       "       0.08593988, 0.07465654, 0.9036464 , 0.62825884, 0.13375878,\n",
       "       0.12110313, 0.31061048, 0.08597516, 0.8867209 , 0.21375596,\n",
       "       0.16315318, 0.08593988, 0.72034266, 0.46197861, 0.1404246 ,\n",
       "       0.7223846 , 0.4649041 , 0.08746253, 0.25033468, 0.16887743,\n",
       "       0.73688871, 0.37445525, 0.87058463, 0.11347568, 0.03769476,\n",
       "       0.24961854, 0.08587837, 0.2189523 , 0.13296692, 0.64314563,\n",
       "       0.09689127, 0.66305187, 0.23936439, 0.53275309, 0.11789892,\n",
       "       0.92175332, 0.09778164, 0.66865557, 0.8055922 , 0.95776975,\n",
       "       0.15293087, 0.37890872, 0.13345441, 0.08593988, 0.44900965,\n",
       "       0.04359699, 0.64463079, 0.08829125, 0.12450494, 0.92667674,\n",
       "       0.32857981, 0.56212073, 0.0797388 , 0.08597516, 0.08591225,\n",
       "       0.72735531, 0.13746769, 0.8437402 , 0.66334965, 0.4791515 ,\n",
       "       0.27392617, 0.32857399, 0.07810852, 0.293357  , 0.34235597,\n",
       "       0.06519777, 0.11729717, 0.61124463, 0.08795589, 0.09784277,\n",
       "       0.44607598, 0.04841235, 0.85721937, 0.09378875, 0.82365959,\n",
       "       0.90018575, 0.55166958, 0.94110409, 0.09358582, 0.0297138 ,\n",
       "       0.94828703, 0.05709845, 0.31849509, 0.63766248, 0.11362955,\n",
       "       0.5274289 , 0.43165349, 0.24433624, 0.10646793, 0.12503235,\n",
       "       0.04201628, 0.06821707, 0.30726699, 0.09082367, 0.80037589,\n",
       "       0.61125618, 0.45229213, 0.09983731, 0.23936439, 0.08760206,\n",
       "       0.12567996, 0.11363565, 0.18997137, 0.11735621, 0.5496763 ,\n",
       "       0.35625869, 0.13241499, 0.81368346, 0.94630646, 0.44123739,\n",
       "       0.31849509, 0.58652108, 0.08586082, 0.13045886, 0.25073506,\n",
       "       0.12105534, 0.13744035, 0.02228606, 0.25985434, 0.08593988,\n",
       "       0.1651244 , 0.09772709, 0.23649126, 0.80800259, 0.05344912,\n",
       "       0.29182207, 0.93923047, 0.0774605 , 0.06976881, 0.37086369,\n",
       "       0.41811204, 0.6394827 , 0.04206661, 0.19586465, 0.48937321,\n",
       "       0.34947652, 0.1286657 , 0.80188156, 0.29302885, 0.46803636,\n",
       "       0.79964462, 0.06335863, 0.14857485, 0.13070021, 0.24526668,\n",
       "       0.89672071, 0.64615628, 0.12910717, 0.27671774, 0.46660118,\n",
       "       0.80776563, 0.18362982, 0.08597516, 0.86683573, 0.96062341,\n",
       "       0.74408203, 0.92948498, 0.20580053, 0.66305187, 0.26266418,\n",
       "       0.41694414, 0.38394604, 0.04571791, 0.74396651, 0.85363866,\n",
       "       0.11971205, 0.73306872, 0.46155375, 0.13744035, 0.13881716,\n",
       "       0.93509327, 0.23936439, 0.31773997, 0.29949342, 0.58187702,\n",
       "       0.41141738, 0.35704259, 0.86281111, 0.08580656, 0.08597516,\n",
       "       0.80776563, 0.65032627, 0.06619008, 0.11371022, 0.55842058,\n",
       "       0.75301565, 0.76598497, 0.90084003, 0.50132041, 0.12615666,\n",
       "       0.11602614, 0.39011682, 0.10108547, 0.88264443, 0.38431104,\n",
       "       0.11118478, 0.55358947, 0.25775198, 0.11705494, 0.05711413,\n",
       "       0.4634557 , 0.96520254, 0.92616754, 0.5731187 , 0.85169208,\n",
       "       0.46085109, 0.60809788, 0.69241587, 0.24861309, 0.8053004 ,\n",
       "       0.17404239, 0.94213696, 0.10665949, 0.08546462, 0.06984444,\n",
       "       0.63585816, 0.85606567, 0.09132424, 0.06320716, 0.48812098,\n",
       "       0.61125618, 0.22472198, 0.19712745, 0.58742852, 0.23010895,\n",
       "       0.18122287, 0.0797121 , 0.65152396, 0.32376107, 0.62400261,\n",
       "       0.70574275, 0.91752201, 0.83070356, 0.92896849, 0.77504026,\n",
       "       0.54007952, 0.12852403, 0.08593988, 0.08746253, 0.15258361,\n",
       "       0.5493159 , 0.13743459, 0.09440289, 0.21869555, 0.47895151,\n",
       "       0.07222858, 0.07434452, 0.88018667, 0.91363667, 0.96347374,\n",
       "       0.21169401, 0.14533949, 0.56879203, 0.25985434, 0.71101422,\n",
       "       0.74604678, 0.69394295, 0.91293879, 0.93272336, 0.08597516,\n",
       "       0.45456696, 0.79808291, 0.23780816, 0.18362982, 0.61152425,\n",
       "       0.58451935, 0.60893798, 0.0907229 , 0.2436832 , 0.89423382,\n",
       "       0.14320004, 0.42750822, 0.39667924, 0.65274103, 0.08731649,\n",
       "       0.11001241, 0.15909437, 0.72020631, 0.72948528, 0.40666201,\n",
       "       0.89701696, 0.56810192, 0.22449871, 0.0797121 , 0.0797121 ,\n",
       "       0.07969698, 0.44652569, 0.11481338, 0.87369425, 0.08236928,\n",
       "       0.06534803, 0.86393801, 0.26242564, 0.04209791, 0.12113669,\n",
       "       0.63317559, 0.13744035, 0.92668855, 0.32266266, 0.25033468,\n",
       "       0.13296692, 0.10993523, 0.08328975, 0.11863037, 0.27875667,\n",
       "       0.41062935, 0.75459078, 0.02228606, 0.52403858, 0.94709938,\n",
       "       0.34597668, 0.12282244, 0.89391453, 0.47675924, 0.22396197,\n",
       "       0.40245391, 0.73206769, 0.12176194, 0.03731787, 0.02228606,\n",
       "       0.08593988, 0.52298243, 0.08480445, 0.08789168, 0.04325815,\n",
       "       0.93149575, 0.06836553, 0.5983877 , 0.87935221, 0.35620396,\n",
       "       0.46893882, 0.75317266, 0.5511804 , 0.09686049, 0.08579228,\n",
       "       0.08591225, 0.08593988, 0.20699286, 0.61124753, 0.1256813 ,\n",
       "       0.58652404, 0.12617207, 0.09772709, 0.11053498, 0.7449811 ,\n",
       "       0.93324194, 0.45297479, 0.32216939, 0.18362982, 0.88571671,\n",
       "       0.24451029, 0.50732134, 0.69504308, 0.89662246, 0.72545433,\n",
       "       0.04954727, 0.61131098, 0.06406538, 0.61125618, 0.18159625,\n",
       "       0.38645408, 0.08630752, 0.17852773, 0.11925037, 0.6931513 ,\n",
       "       0.0798056 , 0.11389008, 0.93972337, 0.23761037, 0.2189523 ,\n",
       "       0.0572731 , 0.87986269, 0.04126826, 0.38490842, 0.39597872,\n",
       "       0.71938603, 0.84103733, 0.08579228, 0.44612994, 0.82206609,\n",
       "       0.89563894, 0.12226811, 0.03610864, 0.04411035, 0.03273151,\n",
       "       0.61125618, 0.1256813 , 0.72034266, 0.05344912, 0.85277227,\n",
       "       0.65368599, 0.10309022, 0.04889789, 0.11371867, 0.21484942,\n",
       "       0.40898351, 0.10780991, 0.61895817, 0.14816012, 0.97363537,\n",
       "       0.77902163, 0.04893434, 0.14537561, 0.1401375 , 0.66305187,\n",
       "       0.08510024, 0.6111726 , 0.22599478, 0.13744035, 0.48044015,\n",
       "       0.86967209, 0.19664268, 0.9436491 , 0.77877463, 0.22396197,\n",
       "       0.15060868, 0.06117641, 0.1256813 , 0.10335976, 0.05528343,\n",
       "       0.08142776, 0.26463745, 0.68200564, 0.58617725, 0.71937622,\n",
       "       0.11011936, 0.13743604, 0.08593988, 0.93651724, 0.33065469,\n",
       "       0.11043482, 0.74359481, 0.94744787, 0.32120691, 0.65168926,\n",
       "       0.51675575, 0.13987734, 0.94421885, 0.9425919 , 0.6907079 ,\n",
       "       0.11779425, 0.94804488, 0.7266941 , 0.08597516, 0.25199357,\n",
       "       0.70415043, 0.3681187 , 0.48102278, 0.24433624, 0.62444947,\n",
       "       0.77392446, 0.68332775, 0.95575229])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict = logreg.predict_proba(x_train)\n",
    "print(train_predict)\n",
    "train_predict = train_predict[:,1]\n",
    "train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(train_predict)):\n",
    "    if(train_predict[i] > 0.55):\n",
    "        train_predict[i] = 1\n",
    "    else:\n",
    "        train_predict[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.30341861011869714, 0.7366255144032922)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = np.sqrt(msle(train_predict, y_train))\n",
    "m = f1_score(train_predict, y_train)\n",
    "l, m\n",
    "\n",
    "'''\n",
    "here the error rate is slightly increased and f1_score value is slightly dec\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[127,  17],\n",
       "       [ 23,  56]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix as cf\n",
    "cf = cf(y_test, test_predict)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.86       144\n",
      "           1       0.77      0.71      0.74        79\n",
      "\n",
      "    accuracy                           0.82       223\n",
      "   macro avg       0.81      0.80      0.80       223\n",
      "weighted avg       0.82      0.82      0.82       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report as cr\n",
    "print(cr ( y_test, test_predict ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parameters of logistic reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03568278,  0.00291173,  1.01367642,  0.14953386, -1.08153753,\n",
       "        1.18549131, -1.10381856,  0.86032941,  1.06209213,  0.35948456,\n",
       "       -0.68458738, -0.79656641, -0.28878937, -0.43029018,  0.12406036,\n",
       "        0.59592578, -0.18184802,  0.21505309, -0.35814802, -0.1431359 ,\n",
       "       -0.17023453,  0.13556721,  0.23703207, -0.29092653])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing coefficients\n",
    "\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Coefficient plot')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 960x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting coeff\n",
    "\n",
    "plt.figure( figsize = (8, 6), dpi =120, facecolor ='w', edgecolor ='b')\n",
    "x = range(len(x_train.columns))\n",
    "c = logreg.coef_.reshape(-1)\n",
    "plt.bar(x, c)\n",
    "plt.xlabel('Varaiables')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('Coefficient plot')\n",
    "\n",
    "'''\n",
    "if the bar is high, which mean those var are more significant\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Age</td>\n",
       "      <td>0.035683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Fare</td>\n",
       "      <td>0.002912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>1.013676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.149534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>1.081538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Sex_female</td>\n",
       "      <td>1.185491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Sex_male</td>\n",
       "      <td>1.103819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>SibSp_0</td>\n",
       "      <td>0.860329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>SibSp_1</td>\n",
       "      <td>1.062092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>SibSp_2</td>\n",
       "      <td>0.359485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>SibSp_3</td>\n",
       "      <td>0.684587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>SibSp_4</td>\n",
       "      <td>0.796566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>SibSp_5</td>\n",
       "      <td>0.288789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>SibSp_8</td>\n",
       "      <td>0.430290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Parch_0</td>\n",
       "      <td>0.124060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Parch_1</td>\n",
       "      <td>0.595926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Parch_2</td>\n",
       "      <td>0.181848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Parch_3</td>\n",
       "      <td>0.215053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Parch_4</td>\n",
       "      <td>0.358148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Parch_5</td>\n",
       "      <td>0.143136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Parch_6</td>\n",
       "      <td>0.170235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.135567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.237032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.290927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Variable  Coefficients\n",
       "0          Age      0.035683\n",
       "1         Fare      0.002912\n",
       "2     Pclass_1      1.013676\n",
       "3     Pclass_2      0.149534\n",
       "4     Pclass_3      1.081538\n",
       "5   Sex_female      1.185491\n",
       "6     Sex_male      1.103819\n",
       "7      SibSp_0      0.860329\n",
       "8      SibSp_1      1.062092\n",
       "9      SibSp_2      0.359485\n",
       "10     SibSp_3      0.684587\n",
       "11     SibSp_4      0.796566\n",
       "12     SibSp_5      0.288789\n",
       "13     SibSp_8      0.430290\n",
       "14     Parch_0      0.124060\n",
       "15     Parch_1      0.595926\n",
       "16     Parch_2      0.181848\n",
       "17     Parch_3      0.215053\n",
       "18     Parch_4      0.358148\n",
       "19     Parch_5      0.143136\n",
       "20     Parch_6      0.170235\n",
       "21  Embarked_C      0.135567\n",
       "22  Embarked_Q      0.237032\n",
       "23  Embarked_S      0.290927"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#coeffs of respective var\n",
    "\n",
    "Coeffs = pd.DataFrame({\n",
    "    'Variable': x_train.columns,\n",
    "    'Coefficients' :abs(c)\n",
    "})\n",
    "Coeffs.head(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>1.013676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>1.081538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Sex_female</td>\n",
       "      <td>1.185491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Sex_male</td>\n",
       "      <td>1.103819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>SibSp_0</td>\n",
       "      <td>0.860329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>SibSp_1</td>\n",
       "      <td>1.062092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>SibSp_2</td>\n",
       "      <td>0.359485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>SibSp_3</td>\n",
       "      <td>0.684587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>SibSp_4</td>\n",
       "      <td>0.796566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>SibSp_8</td>\n",
       "      <td>0.430290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Parch_1</td>\n",
       "      <td>0.595926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Parch_4</td>\n",
       "      <td>0.358148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Variable  Coefficients\n",
       "2     Pclass_1      1.013676\n",
       "4     Pclass_3      1.081538\n",
       "5   Sex_female      1.185491\n",
       "6     Sex_male      1.103819\n",
       "7      SibSp_0      0.860329\n",
       "8      SibSp_1      1.062092\n",
       "9      SibSp_2      0.359485\n",
       "10     SibSp_3      0.684587\n",
       "11     SibSp_4      0.796566\n",
       "13     SibSp_8      0.430290\n",
       "15     Parch_1      0.595926\n",
       "18     Parch_4      0.358148"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting var with high coeff\n",
    "\n",
    "sig_var = Coeffs[Coeffs.Coefficients > 0.3 ] \n",
    "sig_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>SibSp_3</th>\n",
       "      <th>SibSp_4</th>\n",
       "      <th>SibSp_8</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass_1  Pclass_3  Sex_female  Sex_male  SibSp_0  SibSp_1  SibSp_2  \\\n",
       "0         0         1           0         1        0        1        0   \n",
       "1         1         0           1         0        0        1        0   \n",
       "2         0         1           1         0        1        0        0   \n",
       "3         1         0           1         0        0        1        0   \n",
       "4         0         1           0         1        1        0        0   \n",
       "\n",
       "   SibSp_3  SibSp_4  SibSp_8  Parch_1  Parch_4  \n",
       "0        0        0        0        0        0  \n",
       "1        0        0        0        0        0  \n",
       "2        0        0        0        0        0  \n",
       "3        0        0        0        0        0  \n",
       "4        0        0        0        0        0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset  = data[sig_var['Variable'].values]\n",
    "subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((668, 12), (223, 12), (668,), (223,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# splitting the data\n",
    "\n",
    "x_train, x_test, y_train, y_test =train_test_split (subset, y, random_state = 56)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating an instance of logistic fun\n",
    "\n",
    "logreg = logReg()\n",
    "\n",
    "#fitting the model\n",
    "\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3284602804296973, 0.7011952191235059)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making predictions using predict fun\n",
    "\n",
    "train_predict = logreg.predict(x_train)\n",
    "l = np.sqrt(msle(train_predict, y_train))\n",
    "m = f1_score(train_predict, y_train) \n",
    "l, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2666428849015341, 0.7755102040816326)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = logreg.predict(x_test)\n",
    "l = np.sqrt(msle(test_predict, y_test))\n",
    "m = f1_score(test_predict, y_test) \n",
    "l, m\n",
    "\n",
    "'''\n",
    "these prediction values are only based on significant data\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45024456, 0.54975544],\n",
       "       [0.89378293, 0.10621707],\n",
       "       [0.89378293, 0.10621707],\n",
       "       ...,\n",
       "       [0.23612983, 0.76387017],\n",
       "       [0.52159333, 0.47840667],\n",
       "       [0.05964939, 0.94035061]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making predictions using predict_proba fun\n",
    "\n",
    "train_predict = logreg.predict_proba(x_train)\n",
    "train_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (2!=1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-f6838155169f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_log_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \"\"\"\n\u001b[0;32m    321\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 322\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    323\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         raise ValueError(\"y_true and y_pred have different number of output \"\n\u001b[1;32m---> 96\u001b[1;33m                          \"({0}!={1})\".format(y_true.shape[1], y_pred.shape[1]))\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0mn_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (2!=1)"
     ]
    }
   ],
   "source": [
    "test_predict = logreg.predict_proba(x_test)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
